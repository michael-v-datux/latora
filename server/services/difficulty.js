/**
 * server/services/difficulty.js â€” Difficulty Engine v2
 *
 * ĞÑ€Ñ…Ñ–Ñ‚ĞµĞºÑ‚ÑƒÑ€Ğ°:
 *   FinalScore = clamp(BaseScore + AI_Adjustment, 0, 100)
 *
 *   1. BaseScore   â€” Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹, ÑÑ‚Ğ°Ğ±Ñ–Ğ»ÑŒĞ½Ğ¸Ğ¹, Ğ´ĞµÑˆĞµĞ²Ğ¸Ğ¹ (Ğ±ĞµĞ· LLM)
 *      ĞšĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¸: CEFR numeric Â· frequency_band Â· polysemy_level Â·
 *                  morph_complexity Â· word_length Â· phrase_flag
 *
 *   2. AI Adjustment Layer â€” Claude Haiku Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” Ğ¢Ğ†Ğ›Ğ¬ĞšĞ˜:
 *      adjustment (-15â€¦+15) Â· confidence (0â€“100) Â· short_reason
 *      (ĞĞ• Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¹ difficulty â€” ĞºĞ¾Ğ½Ñ‚Ñ€Ğ¾Ğ»ÑŒ Ğ·Ğ°Ğ»Ğ¸ÑˆĞ°Ñ”Ñ‚ÑŒÑÑ Ñƒ Ğ´Ğ²Ğ¸Ğ¶ĞºÑƒ)
 *
 *   3. confidence_score â€” Ğ·Ğ²Ğ°Ğ¶ĞµĞ½Ğ° Ğ¼ĞµÑ‚Ñ€Ğ¸ĞºĞ° Ğ½Ğ°Ğ´Ñ–Ğ¹Ğ½Ğ¾ÑÑ‚Ñ–
 *
 * Personal Modifier Layer Ğ¶Ğ¸Ğ²Ğµ Ñƒ srsService.js Ñ– Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ…Ğ¾Ğ²ÑƒÑ”Ñ‚ÑŒÑÑ
 * Ğ¿Ñ€Ğ¸ ĞºĞ¾Ğ¶Ğ½Ğ¾Ğ¼Ñƒ Ğ¿Ğ¾Ğ²Ñ‚Ğ¾Ñ€ĞµĞ½Ğ½Ñ– (Ğ½Ğµ Ğ¿Ñ€Ğ¸ Ğ¿ĞµÑ€ĞµĞºĞ»Ğ°Ğ´Ñ–).
 */

const Anthropic = require('@anthropic-ai/sdk');

let anthropic;
try {
  anthropic = new Anthropic({ apiKey: process.env.ANTHROPIC_API_KEY });
} catch (e) {
  console.warn('âš ï¸  Anthropic API Ğ½Ğµ Ğ½Ğ°Ğ»Ğ°ÑˆÑ‚Ğ¾Ğ²Ğ°Ğ½Ğ¾. AI-adjustment Ğ±ÑƒĞ´Ğµ Ğ½ĞµĞ´Ğ¾ÑÑ‚ÑƒĞ¿Ğ½Ğ¸Ğ¹.');
}

// â”€â”€â”€ CEFR â†” Ñ‡Ğ¸ÑĞ»Ğ¾Ğ²Ğ¸Ğ¹ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

const CEFR_TO_NUM = { A1: 1, A2: 2, B1: 3, B2: 4, C1: 5, C2: 6 };
const CEFR_ORDER  = ['A1','A2','B1','B2','C1','C2'];

function cefrToNum(level) {
  return CEFR_TO_NUM[String(level).toUpperCase()] ?? 3; // default B1
}

function scoreToCefr(score) {
  if (score <= 17) return 'A1';
  if (score <= 33) return 'A2';
  if (score <= 50) return 'B1';
  if (score <= 66) return 'B2';
  if (score <= 83) return 'C1';
  return 'C2';
}

// â”€â”€â”€ Ğ”ĞµÑ‚ĞµÑ€Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ BaseScore â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * ĞŸÑ–Ğ´Ñ€Ğ°Ñ…ÑƒĞ½Ğ¾Ğº ÑĞºĞ»Ğ°Ğ´Ñ–Ğ² (ÑĞ¿Ñ€Ğ¾Ñ‰ĞµĞ½Ğ¸Ğ¹ Ğ°Ğ»Ğ³Ğ¾Ñ€Ğ¸Ñ‚Ğ¼ Ğ´Ğ»Ñ Ğ»Ğ°Ñ‚Ğ¸Ğ½Ğ¸Ñ†Ñ– / ĞºĞ¸Ñ€Ğ¸Ğ»Ğ¸Ñ†Ñ–)
 */
function countSyllables(word) {
  const w = word.toLowerCase();
  if (w.length <= 3) return 1;
  // ĞšĞ¸Ñ€Ğ¸Ğ»Ğ¸Ñ†Ñ: Ğ³Ğ¾Ğ»Ğ¾ÑĞ½Ñ– Ğ° Ğµ Ñ” Ğ¸ Ñ– Ñ— Ğ¾ Ñƒ Ñ Ñ
  if (/[\u0400-\u04FF]/.test(w)) {
    const m = w.match(/[Ğ°ĞµÑ”Ğ¸Ñ–Ñ—Ğ¾ÑƒÑÑ]/g);
    return m ? m.length : 1;
  }
  // Ğ›Ğ°Ñ‚Ğ¸Ğ½Ğ¸Ñ†Ñ
  let cleaned = w.replace(/(?:[^laeiouy]es|ed|[^laeiouy]e)$/, '').replace(/^y/, '');
  const m = cleaned.match(/[aeiouy]{1,2}/g);
  return m ? m.length : 1;
}

/**
 * frequency_band (1â€“5) â€” ĞµĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ° Ğ·Ğ° Ğ´Ğ¾Ğ²Ğ¶Ğ¸Ğ½Ğ¾Ñ Ñ‚Ğ° ÑĞ¸Ğ»Ğ°Ğ±Ğ°Ğ¼Ğ¸ (Ğ±ĞµĞ· ĞºĞ¾Ñ€Ğ¿ÑƒÑÑƒ).
 * Ğ ĞµĞ°Ğ»ÑŒĞ½Ğ¸Ğ¹ ĞºĞ¾Ñ€Ğ¿ÑƒÑĞ½Ğ¸Ğ¹ rank Ğ¼Ğ¾Ğ¶Ğµ Ğ·Ğ°Ğ¼Ñ–Ğ½Ğ¸Ñ‚Ğ¸ Ñ†Ğµ Ğ¿Ğ¾Ğ»Ğµ Ğ¿Ñ–Ğ·Ğ½Ñ–ÑˆĞµ.
 * 1 = Ğ´ÑƒĞ¶Ğµ Ñ‡Ğ°ÑÑ‚Ğµ, 5 = Ñ€Ñ–Ğ´ĞºÑ–ÑĞ½Ğµ
 */
function estimateFrequencyBand(word) {
  const len = word.length;
  const syl = countSyllables(word);
  // ĞšĞ¾Ñ€Ğ¾Ñ‚ĞºÑ– ÑĞ»Ğ¾Ğ²Ğ° Ğ·Ğ°Ğ·Ğ²Ğ¸Ñ‡Ğ°Ğ¹ Ñ‡Ğ°ÑÑ‚Ñ–ÑˆÑ–
  if (len <= 4 && syl === 1) return 1;
  if (len <= 6 && syl <= 2) return 2;
  if (len <= 9 && syl <= 3) return 3;
  if (len <= 12 && syl <= 4) return 4;
  return 5;
}

/**
 * polysemy_level (1â€“5) â€” ĞµĞ²Ñ€Ğ¸ÑÑ‚Ğ¸ĞºĞ° (ÑĞ¿Ñ€Ğ°Ğ²Ğ¶Ğ½Ñ–Ğ¹ Ñ€Ñ–Ğ²ĞµĞ½ÑŒ Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ” AI)
 */
function estimatePolysemyLevel(word, partOfSpeech) {
  // Ğ†Ğ¼ĞµĞ½Ğ½Ğ¸ĞºĞ¸ Ñ‚Ğ° Ğ´Ñ–Ñ”ÑĞ»Ğ¾Ğ²Ğ° Ğ·Ğ°Ğ·Ğ²Ğ¸Ñ‡Ğ°Ğ¹ Ğ±Ñ–Ğ»ÑŒÑˆ Ğ¿Ğ¾Ğ»Ñ–ÑĞµĞ¼Ğ°Ğ½Ñ‚Ğ¸Ñ‡Ğ½Ñ–
  const pos = (partOfSpeech || '').toLowerCase();
  if (['noun','verb'].includes(pos)) return 3;
  if (['adjective','adverb'].includes(pos)) return 2;
  return 2;
}

/**
 * morph_complexity (1â€“5) â€” Ğ¿Ñ€Ğ°Ğ²Ğ¸Ğ»Ğ¾-Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ°Ğ½Ğ° Ğ¾Ñ†Ñ–Ğ½ĞºĞ°
 */
function morphComplexity(word) {
  const w = word.toLowerCase();
  let score = 1;
  // Ğ¡ÑƒÑ„Ñ–ĞºÑĞ¸ Ñ‰Ğ¾ Ğ¿Ñ–Ğ´Ğ²Ğ¸Ñ‰ÑƒÑÑ‚ÑŒ ÑĞºĞ»Ğ°Ğ´Ğ½Ñ–ÑÑ‚ÑŒ
  const complexSuffixes = [
    'tion','sion','ness','ment','ity','ous','ious','eous',
    'ance','ence','ful','less','able','ible','ish','ise','ize',
  ];
  for (const sfx of complexSuffixes) {
    if (w.endsWith(sfx)) { score += 1; break; }
  }
  // Ğ¡ĞºĞ»Ğ°Ğ´Ğ½Ñ– Ğ±ÑƒĞºĞ²Ğ¾ÑĞ¿Ğ¾Ğ»ÑƒÑ‡ĞµĞ½Ğ½Ñ Ğ´Ğ»Ñ ÑĞ»Ğ¾Ğ²'ÑĞ½ÑÑŒĞºĞ¾Ğ¼Ğ¾Ğ²Ğ½Ğ¸Ñ…
  const hardClusters = ['th','wh','ough','sch','tch','dge','wr','kn','ph','gh'];
  let clusterHits = 0;
  for (const cl of hardClusters) {
    if (w.includes(cl)) clusterHits++;
  }
  score += Math.min(2, clusterHits);

  // Ğ”Ğ¾Ğ²Ğ³Ñ– ÑĞ»Ğ¾Ğ²Ğ° â†’ ÑĞºĞ»Ğ°Ğ´Ğ½Ñ–ÑˆĞ° Ğ¼Ğ¾Ñ€Ñ„Ğ¾Ğ»Ğ¾Ğ³Ñ–Ñ
  if (word.length > 12) score += 1;

  return Math.min(5, score);
}

/**
 * phrase_flag â€” true ÑĞºÑ‰Ğ¾ ÑĞ»Ğ¾Ğ²Ğ¾ Ğ¼Ñ–ÑÑ‚Ğ¸Ñ‚ÑŒ Ğ¿Ñ€Ğ¾Ğ±Ñ–Ğ» Ğ°Ğ±Ğ¾ Ñ” ÑĞºĞ»Ğ°Ğ´Ğ½Ğ¸Ğ¼ Ğ²Ğ¸Ñ€Ğ°Ğ·Ğ¾Ğ¼
 */
function detectPhrase(word) {
  return word.trim().includes(' ') || word.includes('-');
}

/**
 * ĞÑĞ½Ğ¾Ğ²Ğ½Ğ¸Ğ¹ Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ BaseScore (0â€“100)
 *
 * Ğ’Ğ°Ğ³Ğ¸ Ğ¿Ñ–Ğ´Ñ–Ğ±Ñ€Ğ°Ğ½Ñ– Ñ‰Ğ¾Ğ±:
 *  - A1/A2 â†’ 0â€“33
 *  - B1/B2 â†’ 34â€“66
 *  - C1/C2 â†’ 67â€“100
 */
function computeBaseScore({ word, cefrNum, frequencyBand, polysemyLevel, morphComplexityVal, phraseFlag }) {
  // ĞĞ¾Ñ€Ğ¼Ğ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ ĞºĞ¾Ğ¶ĞµĞ½ ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚ Ğ´Ğ¾ 0â€“1
  const cefrScaled    = (cefrNum - 1)          / 5;           // 0=A1, 1=C2
  const freqScaled    = (frequencyBand - 1)    / 4;           // 0=common, 1=rare
  const polyScaled    = (polysemyLevel - 1)    / 4;
  const morphScaled   = (morphComplexityVal - 1) / 4;
  const lengthRaw     = Math.min(word.length, 15);
  const lengthScaled  = (lengthRaw - 2) / 13;                 // Ğ½Ğ¾Ñ€Ğ¼Ğ°Ğ»Ñ–Ğ·ÑƒÑ”Ğ¼Ğ¾ 2â€“15 chars
  const phraseAdd     = phraseFlag ? 0.06 : 0;

  // Ğ’Ğ°Ğ³Ğ¸ (ÑÑƒĞ¼Ğ° â‰ˆ 1.0)
  const W_CEFR   = 0.35;
  const W_FREQ   = 0.20;
  const W_POLY   = 0.15;
  const W_MORPH  = 0.15;
  const W_LENGTH = 0.15;

  const raw =
    W_CEFR  * cefrScaled   +
    W_FREQ  * freqScaled   +
    W_POLY  * polyScaled   +
    W_MORPH * morphScaled  +
    W_LENGTH * lengthScaled +
    phraseAdd;

  return Math.round(Math.min(1, Math.max(0, raw)) * 100);
}

// â”€â”€â”€ Claude JSON-Ğ¿Ğ°Ñ€ÑĞ¸Ğ½Ğ³ (robust) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

function parseClaudeJson(rawText) {
  if (!rawText || typeof rawText !== 'string') throw new Error('Claude returned empty response');
  let text = rawText.trim();

  if (text.includes('```')) {
    const s = text.indexOf('```');
    const e = text.indexOf('```', s + 3);
    if (s !== -1 && e > s) {
      let inner = text.slice(s + 3, e).trim();
      inner = inner.replace(/^json\s*/i, '').trim();
      text = inner;
    }
  }

  try { return JSON.parse(text); } catch (_) {}

  const s = text.indexOf('{');
  const e = text.lastIndexOf('}');
  if (s !== -1 && e > s) {
    try { return JSON.parse(text.slice(s, e + 1)); } catch (_) {}
  }

  throw new Error(`Claude response is not valid JSON. Preview: "${text.slice(0, 200)}"`);
}

// â”€â”€â”€ AI Adjustment Layer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * Ğ—Ğ°Ğ¿Ğ¸Ñ‚ Ğ´Ğ¾ Claude Haiku.
 * AI ĞĞ• Ğ³ĞµĞ½ĞµÑ€ÑƒÑ” Ğ¿Ğ¾Ğ²Ğ½Ğ¸Ğ¹ difficulty â€” Ñ‚Ñ–Ğ»ÑŒĞºĞ¸ adjustment + confidence + reason.
 *
 * @returns {{ adjustment: number, confidence: number, reason: string,
 *             cefr_level: string, part_of_speech: string,
 *             transcription: string, example_sentence: string,
 *             example_sentence_target: string,
 *             polysemy_level: number, definition: string, definition_uk: string }}
 */
async function getAiAdjustment({ word, translation, sourceLang, targetLang, baseScore }) {
  const srcLabel = sourceLang || 'EN';
  const tgtLabel = targetLang || 'UK';

  // Ğ§Ğ¸ Ğ¿Ğ¾Ñ‚Ñ€Ñ–Ğ±Ğ½Ğµ Ğ²Ğ¸Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ?
  // Ğ¢Ğ°Ğº â€” Ğ·Ğ°Ğ²Ğ¶Ğ´Ğ¸ (UI Ğ¼Ğ¾Ğ¶Ğµ Ğ±ÑƒÑ‚Ğ¸ UK Ğ½Ğ°Ğ²Ñ–Ñ‚ÑŒ ÑĞºÑ‰Ğ¾ Ğ²Ğ¸Ğ²Ñ‡Ğ°ÑÑ‚ÑŒ Ğ¿Ğ¾Ğ»ÑŒÑÑŒĞºÑƒ)
  const needsUkDef = true;

  const prompt = `You are an expert in language teaching for ${tgtLabel}-speaking students learning ${srcLabel}.

The word/phrase "${word}" (translation: "${translation}") has a base difficulty score of ${baseScore}/100.

Respond ONLY with a valid JSON object:
{
  "adjustment": 5,
  "confidence": 78,
  "reason": "One concise sentence explaining the main difficulty nuance.",
  "cefr_level": "B2",
  "part_of_speech": "noun",
  "transcription": "/ËˆwÉœËrd/",
  "example_sentence": "A natural example sentence in ${srcLabel} using the word.",
  "example_sentence_target": "A natural example sentence in ${tgtLabel} using the translated word '${translation}'.",
  "polysemy_level": 3,
  "definition": "A concise English-language definition of the meaning.",
  "definition_uk": "Ğ¡Ñ‚Ğ¸ÑĞ»Ğµ Ğ²Ğ¸Ğ·Ğ½Ğ°Ñ‡ĞµĞ½Ğ½Ñ ÑĞ»Ğ¾Ğ²Ğ° ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ Ğ¼Ğ¾Ğ²Ğ¾Ñ."
}

Rules:
- adjustment: integer from -15 to +15. Positive = harder than base, negative = easier.
  Adjust for: semantic nuance, false friends, cultural context, irregular forms.
- confidence: 0â€“100 (your certainty about this assessment)
- cefr_level: A1 A2 B1 B2 C1 C2
- polysemy_level: 1(mono-semantic)â€“5(highly polysemous)
- transcription: IPA format, ${srcLabel} pronunciation
- example_sentence: in ${srcLabel} (source language), natural usage of "${word}"
- example_sentence_target: in ${tgtLabel} (target language), natural usage of the translated word "${translation}". Must be a different sentence from example_sentence.
- definition: a short, clear English definition of the word/phrase/idiom meaning.
  For single words: dictionary-style (e.g. "very silly; deserving to be laughed at").
  For idioms/fixed expressions: explain figurative meaning.
  For collocations/phrases: brief contextual description.
  Keep it under 120 characters. Do not include the word itself in the definition.
- definition_uk: same as definition but in Ukrainian. Keep under 120 characters.`;

  const message = await anthropic.messages.create({
    model: 'claude-haiku-4-5-20251001',
    max_tokens: 500,
    messages: [{ role: 'user', content: prompt }],
  });

  const raw = message.content[0]?.text?.trim() || '';
  return parseClaudeJson(raw);
}

// â”€â”€â”€ Confidence Score â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * confidence_score = weighted(AI confidence, CEFR alignment, frequency reliability)
 */
function computeConfidence({ aiConfidence, aiCefr, baseScore }) {
  const baseCefr = scoreToCefr(baseScore);
  const cefrMatch = aiCefr === baseCefr ? 1.0 : (Math.abs(CEFR_ORDER.indexOf(aiCefr) - CEFR_ORDER.indexOf(baseCefr)) <= 1 ? 0.7 : 0.4);
  const normalized = Math.min(100, Math.max(0, aiConfidence));
  return Math.round(normalized * 0.7 + cefrMatch * 30);
}

// â”€â”€â”€ ĞŸÑƒĞ±Ğ»Ñ–Ñ‡Ğ½Ğ¸Ğ¹ API â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

/**
 * assessDifficulty â€” Ğ³Ğ¾Ğ»Ğ¾Ğ²Ğ½Ğ° Ñ„ÑƒĞ½ĞºÑ†Ñ–Ñ Difficulty Engine v2
 *
 * @param {string} word
 * @param {string} translation
 * @param {{ sourceLang?: string, targetLang?: string }} opts
 * @returns {{
 *   cefr_level: string,
 *   difficulty_score: number,        // FinalScore (0â€“100)
 *   base_score: number,
 *   ai_adjustment: number,
 *   confidence_score: number,
 *   frequency_band: number,
 *   polysemy_level: number,
 *   morph_complexity: number,
 *   phrase_flag: boolean,
 *   factors: object,
 *   example_sentence: string|null,         // Ñƒ source_lang (Ğ½Ğ°Ğ¿Ñ€. EN)
 *   example_sentence_target: string|null,  // Ñƒ target_lang (Ğ½Ğ°Ğ¿Ñ€. PL, DE â€¦)
 *   part_of_speech: string|null,
 *   transcription: string|null,
 *   definition: string|null,               // Ğ°Ğ½Ğ³Ğ»Ñ–Ğ¹ÑÑŒĞºĞ¾Ñ
 *   definition_uk: string|null,            // ÑƒĞºÑ€Ğ°Ñ—Ğ½ÑÑŒĞºĞ¾Ñ
 * }}
 */
async function assessDifficulty(word, translation, opts = {}) {
  const { sourceLang = 'EN', targetLang = 'UK' } = opts;

  // â”€â”€ 1. Ğ”ĞµÑ‚ĞµÑ€Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ñ– ĞºĞ¾Ğ¼Ğ¿Ğ¾Ğ½ĞµĞ½Ñ‚Ğ¸ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  const phraseFlag        = detectPhrase(word);
  const frequencyBand     = estimateFrequencyBand(word);
  const morphComplexityVal = morphComplexity(word);
  // polysemy â€” Ğ¿Ğ¾Ğ¿ĞµÑ€ĞµĞ´Ğ½Ñ–Ğ¹ estimate, Ğ±ÑƒĞ´Ğµ ÑƒÑ‚Ğ¾Ñ‡Ğ½ĞµĞ½Ğ¸Ğ¹ AI
  const polysemyEstimate  = estimatePolysemyLevel(word, null);

  // Ğ¢Ğ¸Ğ¼Ñ‡Ğ°ÑĞ¾Ğ²Ğ¸Ğ¹ CEFR (Ğ· Ğ±Ğ°Ğ·Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ°Ğ»Ğ³Ğ¾) Ğ´Ğ»Ñ Ñ€Ğ¾Ğ·Ñ€Ğ°Ñ…ÑƒĞ½ĞºÑƒ BaseScore
  // Ğ¿Ñ–ÑĞ»Ñ AI Ğ¾Ñ‚Ñ€Ğ¸Ğ¼Ğ°Ñ”Ğ¼Ğ¾ Ñ‚Ğ¾Ñ‡Ğ½Ñ–ÑˆĞ¸Ğ¹ CEFR
  const prelimCefrNum = 3; // B1 ÑĞº default Ğ´Ğ¾ AI Ğ²Ñ–Ğ´Ğ¿Ğ¾Ğ²Ñ–Ğ´Ñ–

  const baseScore = computeBaseScore({
    word,
    cefrNum:          prelimCefrNum,
    frequencyBand,
    polysemyLevel:    polysemyEstimate,
    morphComplexityVal,
    phraseFlag,
  });

  // â”€â”€ 2. AI Adjustment â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
  if (!anthropic) {
    // No AI â€” Ğ¿Ğ¾Ğ²ĞµÑ€Ñ‚Ğ°Ñ”Ğ¼Ğ¾ Ğ´ĞµÑ‚ĞµÑ€Ğ¼Ñ–Ğ½Ñ–ÑÑ‚Ğ¸Ñ‡Ğ½Ğ¸Ğ¹ Ñ€ĞµĞ·ÑƒĞ»ÑŒÑ‚Ğ°Ñ‚
    return {
      cefr_level:               scoreToCefr(baseScore),
      difficulty_score:         baseScore,
      base_score:               baseScore,
      ai_adjustment:            0,
      confidence_score:         40,
      frequency_band:           frequencyBand,
      polysemy_level:           polysemyEstimate,
      morph_complexity:         morphComplexityVal,
      phrase_flag:              phraseFlag,
      factors:                  { source: 'deterministic_only' },
      example_sentence:         null,
      example_sentence_target:  null,
      part_of_speech:           null,
      transcription:            null,
      definition:               null,
      definition_uk:            null,
    };
  }

  try {
    const ai = await getAiAdjustment({ word, translation, sourceLang, targetLang, baseScore });

    // Clamp adjustment
    const adjustment = Math.min(15, Math.max(-15, Math.round(ai.adjustment ?? 0)));

    // ĞŸĞµÑ€ĞµÑ€Ğ°Ñ…ÑƒÑ”Ğ¼Ğ¾ BaseScore Ğ· AI CEFR
    const aiCefrNum = cefrToNum(ai.cefr_level || 'B1');
    const refinedBase = computeBaseScore({
      word,
      cefrNum:          aiCefrNum,
      frequencyBand,
      polysemyLevel:    Math.min(5, Math.max(1, ai.polysemy_level ?? polysemyEstimate)),
      morphComplexityVal,
      phraseFlag,
    });

    const finalScore      = Math.min(100, Math.max(0, refinedBase + adjustment));
    const polysemyFinal   = Math.min(5, Math.max(1, Math.round(ai.polysemy_level ?? polysemyEstimate)));
    const confidenceScore = computeConfidence({
      aiConfidence: ai.confidence ?? 60,
      aiCefr:       ai.cefr_level || 'B1',
      baseScore:    refinedBase,
    });

    return {
      cefr_level:               ai.cefr_level || scoreToCefr(finalScore),
      difficulty_score:         finalScore,
      base_score:               refinedBase,
      ai_adjustment:            adjustment,
      confidence_score:         confidenceScore,
      frequency_band:           frequencyBand,
      polysemy_level:           polysemyFinal,
      morph_complexity:         morphComplexityVal,
      phrase_flag:              phraseFlag,
      factors: {
        polysemy:               polysemyFinal,
        false_friends:          ai.false_friends ?? false,
        phonetic_difficulty:    ai.phonetic_difficulty ?? null,
        cultural_context:       ai.cultural_context ?? null,
        morphological_complexity: morphComplexityVal,
        source: 'v2_ai+deterministic',
        ai_reason: ai.reason || null,
      },
      example_sentence:         ai.example_sentence         || null,
      example_sentence_target:  ai.example_sentence_target  || null,
      part_of_speech:           ai.part_of_speech            || null,
      transcription:            ai.transcription             || null,
      definition:               ai.definition                || null,
      definition_uk:            ai.definition_uk             || null,
    };
  } catch (error) {
    console.error('ğŸ¤– AI adjustment failed, using deterministic result:', error.message);
    return {
      cefr_level:               scoreToCefr(baseScore),
      difficulty_score:         baseScore,
      base_score:               baseScore,
      ai_adjustment:            0,
      confidence_score:         35,
      frequency_band:           frequencyBand,
      polysemy_level:           polysemyEstimate,
      morph_complexity:         morphComplexityVal,
      phrase_flag:              phraseFlag,
      factors:                  { source: 'deterministic_fallback', error: error.message },
      example_sentence:         null,
      example_sentence_target:  null,
      part_of_speech:           null,
      transcription:            null,
      definition:               null,
      definition_uk:            null,
    };
  }
}

// Ğ—Ğ°Ğ»Ğ¸ÑˆĞ°Ñ”Ğ¼Ğ¾ Ğ´Ğ»Ñ Ğ·Ğ²Ğ¾Ñ€Ğ¾Ñ‚Ğ½Ğ¾Ñ— ÑÑƒĞ¼Ñ–ÑĞ½Ğ¾ÑÑ‚Ñ– Ğ· backfill ÑĞºÑ€Ğ¸Ğ¿Ñ‚Ğ¾Ğ¼
function getBaseScore(word, cefrNum = 3, polysemy = 2) {
  return computeBaseScore({
    word,
    cefrNum,
    frequencyBand:     estimateFrequencyBand(word),
    polysemyLevel:     polysemy,
    morphComplexityVal: morphComplexity(word),
    phraseFlag:        detectPhrase(word),
  });
}

module.exports = {
  assessDifficulty,
  // Ğ£Ñ‚Ğ¸Ğ»Ñ–Ñ‚Ğ¸ (Ğ´Ğ»Ñ backfill Ñ‚Ğ° Ñ‚ĞµÑÑ‚Ñ–Ğ²)
  getBaseScore,
  scoreToCefr,
  cefrToNum,
  computeBaseScore,
  estimateFrequencyBand,
  estimatePolysemyLevel,
  morphComplexity,
  detectPhrase,
};
